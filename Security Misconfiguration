OWASP #5 - Security Misconfiguration

This is commonly a result of insecure default configurations, incomplete or ad hoc configurations, open cloud storage, misconfigured HTTP headers and verbose error messages containing sensitive information. Not only must all OS, frameworks, libraries and applications be securely configured, they must be patched/ upgraded in a timely fashion.

Some examples:

1. Improperly configured permissions/ missing appropriate security hardening across any part of the application stack (network services, platform, web server, application server, database, frameworks, custom code, pre-installed virtual machines, containers or storage) - repeatable hardening processes should be introduced to make it fast and easy to deploy to another environment that is properly locked down and secure.

2. Default accounts and their passwords are still enabled and unchanged. 

3. Unnecessary features are enabled or installed (eg. unnecessary ports, services, pages, accounts and privileges) -> keep a minimal platform, remove or do not install unusused features or frameworks.

4. A segmented application architecture that provides effective, secure separation between components or tenants.

5. Error handling reveals stack traces or other informative error messages to users. 

6. The software is out of date or vulnerable or latest security features are disabled or not configured securely. Configurations must be updated according to updates or patches as part of the patch management process. 

7. The server does not send security headers or directives. This describes the HTTP response headers that our application can use to increase the security of the application:

- HTTP Strict Transport Security (HSTS): This allows web servers to declare that web browsers (or other complying web agents) should only interact with it using secure HTTPS connections and never via the insecure HTTP protocol. This helps prevent against protocol downgrade attacks and cookie hijacking. 

Values:
max-age(seconds) - The time in seconds that the browser should remember that this site is only to be accessed via HTTPS, If an optional parameter is specified, this rule can apply to the site's subdomains as well.


- X-Frame-Options: This frame header improves the protection of web applications against clickjacking. It instructs the browser whether the content can be displayed within frames. This has been replaced with the CSP header.

Values:
deny (i.e. no rendering within a frame)
sameorigin (no rendering if origin mismatch)
allow-from: DOMAIN (allows rendering if framed by frame selected from DOMAIN)

- X-Content-Type-Options: Setting this header will prevent the browser from interpreting files as a different MIME type as to what is specified in the Content-Type HTTP header (eg. treating text/plain as text/css)

Values:
nosniff - will prevent the browser from MIME sniffing a response away from the declared content type.

- Content Security policy (CSP): A primary goal of CSP is to mitigate and report XSS attacks. XSS attacks exploit the browser's trust in the content received from the server. Malicious scripts are executed by the victim's browser because the browser trusts the source of the content, even when it's not coming from where it seems to be coming from.

CSP makes it possible for server administrators to reduce or eliminate the vectors by which XSS can occur by specifying the domains that the browser should consider to be valid sources of executable scripts. A CSP compatible browser will then only execute scripts loaded in source files received from those allowed domains, ignoring all other scripts (including inline scripts and event-handling HTML attributes).

As an ultimate form of protection, sites that want to never allow scripts to be executed can opt to globally disallow script execution.
Completed this Secure Code Warrior Lab: https://portal.securecodewarrior.com/#/coding-labs/lesson/javascript-react-csp-headers:94ef56a6/javascript.react/walkthrough

Using CSP
Configuring Content Security Policy involves adding the Content-Security-Policy HTTP header to a web page and giving it values to control what resources the user agent is allowed to load for that page. For example, a page that uploads and displays images could allow images from anywhere, but restrict a form action to a specific endpoint. A properly designed Content Security Policy helps protect a page against a cross-site scripting attack. This article explains how to construct such headers properly, and provides examples.

Specifying your policy
You can use the Content-Security-Policy HTTP header to specify your policy, like this:

Content-Security-Policy: policy
The policy is a string containing the policy directives describing your Content Security Policy.

Writing a policy
A policy is described using a series of policy directives, each of which describes the policy for a certain resource type or policy area. Your policy should include a default-src policy directive, which is a fallback for other resource types when they don't have policies of their own (for a complete list, see the description of the default-src directive). A policy needs to include a default-src or script-src directive to prevent inline scripts from running, as well as blocking the use of eval(). A policy needs to include a default-src or style-src directive to restrict inline styles from being applied from a <style> element or a style attribute. There are specific directives for a wide variety of types of items, so that each type can have its own policy, including fonts, frames, images, audio and video media, scripts, and workers.

For a complete list of policy directives, see the reference page for the Content-Security-Policy header.

Examples: Common use cases
This section provides examples of some common security policy scenarios.

Example 1: A website administrator wants all content to come from the site's own origin (this excludes subdomains.)
Content-Security-Policy: default-src 'self'

Example 2: A website administrator wants to allow content from a trusted domain and all its subdomains (it doesn't have to be the same domain that the CSP is set on.)
Content-Security-Policy: default-src 'self' example.com *.example.com

Example 3: A website administrator wants to allow users of a web application to include images from any origin in their own content, but to restrict audio or video media to trusted providers, and all scripts only to a specific server that hosts trusted code.
Content-Security-Policy: default-src 'self'; img-src *; media-src example.org example.net; script-src userscripts.example.com

Here, by default, content is only permitted from the document's origin, with the following exceptions:

Images may load from anywhere (note the "*" wildcard).
Media is only allowed from example.org and example.net (and not from subdomains of those sites).
Executable script is only allowed from userscripts.example.com.

Example 4: A website administrator for an online banking site wants to ensure that all its content is loaded using TLS, in order to prevent attackers from eavesdropping on requests.

Content-Security-Policy: default-src https://onlinebanking.example.com
The server permits access only to documents being loaded specifically over HTTPS through the single origin onlinebanking.example.com.

Example 5
A website administrator of a web mail site wants to allow HTML in email, as well as images loaded from anywhere, but not JavaScript or other potentially dangerous content.

Content-Security-Policy: default-src 'self' *.example.com; img-src *
Note that this example doesn't specify a script-src; with the example CSP, this site uses the setting specified by the default-src directive, which means that scripts can be loaded only from the originating server.

Testing your policy
To ease deployment, CSP can be deployed in report-only mode. The policy is not enforced, but any violations are reported to a provided URI. Additionally, a report-only header can be used to test a future revision to a policy without actually deploying it.

You can use the Content-Security-Policy-Report-Only HTTP header to specify your policy, like this:

Content-Security-Policy-Report-Only: policy
If both a Content-Security-Policy-Report-Only header and a Content-Security-Policy header are present in the same response, both policies are honored. The policy specified in Content-Security-Policy headers is enforced while the Content-Security-Policy-Report-Only policy generates reports but is not enforced.

Enabling reporting
By default, violation reports aren't sent. To enable violation reporting, you need to specify the report-to policy directive, providing at least one URI to which to deliver the reports:

Content-Security-Policy: default-src 'self'; report-to http://reportcollector.example.com/collector.cgi
Then you need to set up your server to receive the reports; it can store or process them in whatever manner you determine is appropriate.

Violation report syntax
The report JSON object is sent with an application/csp-report Content-Type and contains the following data:

blocked-uri
The URI of the resource that was blocked from loading by the Content Security Policy. If the blocked URI is from a different origin than the document-uri, then the blocked URI is truncated to contain just the scheme, host, and port.

disposition
Either "enforce" or "report" depending on whether the Content-Security-Policy-Report-Only header or the Content-Security-Policy header is used.

document-uri
The URI of the document in which the violation occurred.

effective-directive
The directive whose enforcement caused the violation. Some browsers may provide different values, such as Chrome providing style-src-elem/style-src-attr, even when the actually enforced directive was style-src.

original-policy
The original policy as specified by the Content-Security-Policy HTTP header.

referrer Deprecated Non-standard
The referrer of the document in which the violation occurred.

script-sample
The first 40 characters of the inline script, event handler, or style that caused the violation. Only applicable to script-src* and style-src* violations, when they contain the 'report-sample'

status-code
The HTTP status code of the resource on which the global object was instantiated.

violated-directive Deprecated
The directive whose enforcement caused the violation. The violated-directive is a historic name for the effective-directive field and contains the same value.

Sample violation report
Let's consider a page located at http://example.com/signup.html. It uses the following policy, disallowing everything but stylesheets from cdn.example.com.

Content-Security-Policy: default-src 'none'; style-src cdn.example.com; report-to /_/csp-reports
The HTML of signup.html looks like this:

<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8" />
    <title>Sign Up</title>
    <link rel="stylesheet" href="css/style.css" />
  </head>
  <body>
    Here be content.
  </body>
</html>
Can you spot the mistake? Stylesheets are allowed to be loaded only from cdn.example.com, yet the website tries to load one from its own origin (http://example.com). A browser capable of enforcing CSP would send the following violation report as a POST request to http://example.com/_/csp-reports, when the document is visited:

JSON
Copy to Clipboard

{
  "csp-report": {
    "blocked-uri": "http://example.com/css/style.css",
    "disposition": "report",
    "document-uri": "http://example.com/signup.html",
    "effective-directive": "style-src-elem",
    "original-policy": "default-src 'none'; style-src cdn.example.com; report-to /_/csp-reports",
    "referrer": "",
    "status-code": 200,
    "violated-directive": "style-src-elem"
  }
}
As you can see, the report includes the full path to the violating resource in blocked-uri. This is not always the case. For example, if the signup.html attempted to load CSS from http://anothercdn.example.com/stylesheet.css, the browser would not include the full path, but only the origin (http://anothercdn.example.com). The CSP specification gives an explanation of this odd behavior. In summary, this is done to prevent leaking sensitive information about cross-origin resources.



- Referer: This header contains an absolute or partial address of the page making the request. This header allows servers to identify where people are visiting them from and is then used for analytics, logging, optimized caching and more. The referer policy governs which referer information should be included with the request made. 

Values:
no-referer (the referer header will be ommitted entirely. No referer information is sent along with requests)
origin (only send the origin of the document as the referer in all cases)
same-origin (referer will be sent for same site origins only)

- Clear-Site-data: This header clears browsing data (cookies, storage, cache) associated with the requesting website. It allows web developers to have more control over the data stored locally by the browser for their origins. For eg. In a logout process, this can ensure that all stored content on a client side are removed.

Values:
cache (the server wishes to remove locally cached data for the origin of the response URL)
cookies (server wishes to remove all cookies for the origin of the response URL. HTTP authentication credentials are also cleared out. This affects the entire registered domain, including subdomains)
* (clear all types of data for the origin of the response)

- Cross-Origin-Embedder Policy: This header prevents any document from loading cross origin sources that's don't explicitly grant the document permission.


If using CSP, how can you still allow some inline JavaScript to run?


Content Security Policy (CSP) is a web security standard that helps prevent various types of attacks, including Cross-Site Scripting (XSS), by allowing website administrators to control which resources (such as scripts, stylesheets, and images) are executed on a web page. By default, CSP blocks inline scripts for security reasons, but there are ways to allow specific inline JavaScript to run while maintaining a strong security posture.

Here are some methods to allow inline JavaScript in the context of a CSP:

nonce Attribute:

You can use the nonce attribute to allow specific inline scripts to run. The nonce (number used once) is a random value that must match the value specified in the CSP header.
Example:

html
Copy code
<script nonce="random_nonce_value">
   // Your inline JavaScript code here
</script>
In the CSP header, you would specify the nonce value:

css
Copy code
Content-Security-Policy: script-src 'nonce-random_nonce_value'
unsafe-inline Directive:

While generally discouraged for security reasons, you can use the unsafe-inline directive to allow all inline scripts. However, this significantly weakens the security provided by CSP, and it is not recommended unless absolutely necessary.
Example:

css
Copy code
Content-Security-Policy: script-src 'unsafe-inline'
Hashes:

You can specify the cryptographic hash (SHA-256, SHA-384, or SHA-512) of a script's source code in the CSP header to allow it to run. This ensures that only scripts with the specified hash values are executed.
Example:

html
Copy code
<script>
   // Your inline JavaScript code here
</script>
In the CSP header:

css
Copy code
Content-Security-Policy: script-src 'sha256-hash_value'
strict-dynamic Directive:

The strict-dynamic directive allows the execution of inline scripts if they are part of a script loaded through an allowed source (e.g., a script with a nonce or hash).
Example:

css
Copy code
Content-Security-Policy: script-src 'strict-dynamic'


If using CSP nonce, how should the nonce be generated and set?

When using the nonce attribute in Content Security Policy (CSP) to allow specific inline scripts to run, it's important to generate a random and unique nonce value for each page load. The nonce value acts as a cryptographic token that associates a specific script tag with the allowed script sources specified in the CSP header.

Here's a general guide on how to generate and set a nonce value in your HTML document:

Generate a Nonce Server-Side:

The nonce value should be generated server-side and included in the HTML response. It's important to use a secure method to generate a random nonce for each request.
Example (using Python):

python
Copy code
import base64
import os

nonce = base64.b64encode(os.urandom(16)).decode('utf-8')
In this example, os.urandom(16) generates 16 bytes of random data, and base64.b64encode converts it into a base64-encoded string.

Include the Nonce in the HTML:

Insert the generated nonce value into the nonce attribute of the inline script tags in your HTML.
Example:

html
Copy code
<script nonce="generated_nonce_value">
   // Your inline JavaScript code here
</script>
Set the CSP Header:

In the HTTP response headers, include the Content-Security-Policy header with the allowed script sources, including the nonce.
Example:

css
Copy code
Content-Security-Policy: script-src 'nonce-generated_nonce_value'
Ensure that the nonce value specified in the CSP header matches the value you generated and included in the HTML.

Dynamic Generation (if needed):

If your web application generates content dynamically and you need to set nonces for inline scripts in multiple places, make sure to generate unique nonces for each location.


How does output sanitization help in mitigating XSS? Why is it better than input encoding?

Output sanitization and input encoding are both crucial techniques for mitigating Cross-Site Scripting (XSS) attacks, but they serve different purposes in web security. Let's explore each approach and understand how output sanitization helps mitigate XSS and why it is often considered better than input encoding in certain contexts.

Input Encoding:

Input encoding involves transforming user-input data before it is stored or processed by the application. The idea is to encode special characters in the input to prevent them from being interpreted as executable code by the browser.
Example:

javascript
Copy code
// Input encoding in JavaScript
var userInput = "<script>alert('XSS')</script>";
var encodedInput = encodeURIComponent(userInput);
However, input encoding is not always sufficient to prevent XSS, especially when rendering user-generated content on the web page. If the application doesn't appropriately decode the input before rendering, the encoded content might still be interpreted as executable code.

Output Sanitization:

Output sanitization, on the other hand, is performed at the point where data is rendered on the web page. It involves inspecting and cleaning the data just before rendering it to the browser, ensuring that any potentially malicious content is neutralized.
Example (in a server-side language like PHP):

php
Copy code
// Output sanitization in PHP
$userInput = "<script>alert('XSS')</script>";
echo htmlspecialchars($userInput, ENT_QUOTES, 'UTF-8');
In this example, htmlspecialchars is used to replace special characters with their HTML entities, preventing them from being interpreted as HTML or script tags.

Advantages of Output Sanitization over Input Encoding:

Context-Aware:

Output sanitization is context-aware, meaning it takes into account the specific context in which data is being rendered (e.g., HTML, attribute values, JavaScript, etc.). This allows for more precise and targeted sanitization.
Prevents Double Encoding:

Input encoding can sometimes lead to double encoding issues, especially when user input goes through multiple stages of processing. Output sanitization, when done correctly, ensures that the data is properly decoded and then sanitized for the specific rendering context.
Granular Control:

Output sanitization provides granular control over how data is sanitized based on the rendering context. Different contexts may require different sanitization strategies, and output sanitization allows developers to apply the appropriate measures.
Defense in Depth:

While input encoding is an essential layer of defense, output sanitization serves as an additional layer in the defense-in-depth strategy. By ensuring that data is clean and safe at the point of rendering, output sanitization minimizes the risk of XSS vulnerabilities.



8. XML External Entities (XXE): Attackers can exploit vulnerable XML processors if they can upload XML or include hostile content in an XML document, exploiting vulnerable code, dependencies or integrations. By default, many older XML processors allow specification of an external entity, a URI that is dereferenced and evaluated during XML parsing. 

Example Attack Scenarios:

XXE can occur in a lot of unexpected places. The easiest way is to upload a malicious file:

Scenario #1: The attacker attempts to extract data from the server
<?xml versions="1.0" encoding="ISO-8859-1"?>
<!DOCTYPE foo [
<!ELEMENT foo ANY >
<!ENTITY xxe SYSTEM "file://etc/passwd">]>
<foo> &xxe; </foo>

Scenario #2: An attacker attempts a denial-of-service attack by including a potentially endless file
<!ENTITY xxe SYSTEM "file://dev/random">]>

Scenario #3: An attacker probes the server's private network by changing the above entity line to 
<!ENTITY xxe SYSTEM "file://192.168.1.1/private">]>

These flaws can basically be used to extract data, execute a remote request on the server, perform a DoS or other attacks. The business impact depends on the protection needs of all affected applications and data.

Is an application vulnerable?

- If the application accepts XML directly or XML uploads, especially from untrusted sources, or inserts untrusted data into XML documents, which is then parsed by a XML processor. 
- If any of the XML processors in the application or SOAP based web services have Document type Definition (DTD) enabled.
- If the application uses SAML for identity processing within federated security or single sign on (SSO) platform. SAML has XML for identity assertions and may be vulnerable.
- If the application uses SOAP prior to version 1.2, it is likely susceptible to XXE attacks if XML entities are being parsed to the SOAP framework.

How to prevent?

- Developer training is essential to identify and mitigate XXE
- Whenever possible, use less complex formats such as JSON and avoid serialization of sensitive data
- Patch or upgrade all XML processors and libraries in use by the application or in the underlying operating system, update SOAP to SOAP 1.2 or higher
- Disable XML external entity and DTD processing in all XML parsers
- Verify that XML or XSL file upload functionality validates incoming XML using XSD validation or similar
- SAST (Static Application Security Testing) Tools can help detect XXE in source code, although manual code reviews are also an alternative in large, complex applications with many integrations
- Implement positive ("whitelisting") server-side input validation, filtering or sanitization to prevent hostile data within XML documents, headers or nodes

If these controls are not possible, consider using virtual patching, API security gateways or web application firewalls (WAF's) to detect, monitor and block XXE attacks.
